{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Users\\wat\\Anaconda2\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input(datapath=\"../dataset/\", train_size=None, test_size=None, image_size=64):\n",
    "    '''\n",
    "    【输入参数】\n",
    "    datapath: 数据集所在的文件夹路径\n",
    "    train_size: 训练集大小，从原训练集中取前train_size个样本,默认为整个训练集大小\n",
    "    test_size: 测试集大小,默认为整个测试集大小\n",
    "    image_size: 用于训练的图片大小\n",
    "    【返回值】\n",
    "    x_train: 训练集特征，即用于训练的图片的集合\n",
    "    y_train: 训练集标签,17列，值为0或1\n",
    "    x_test: 测试集特征\n",
    "    labels: 标签集合，一共17种标签,run_model函数需要用到\n",
    "    df_test: 用于生成提交文件，write_output函数需要用到\n",
    "    '''\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "\n",
    "    df_train = pd.read_csv(datapath + 'train_v2.csv')[:train_size]\n",
    "    df_test = pd.read_csv(datapath + 'sample_submission_v2.csv')[:test_size]\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "    label_map = {l: i for i, l in enumerate(labels)}\n",
    "    \n",
    "    for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "        img = cv2.imread(datapath + 'train-jpg/{}.jpg'.format(f))\n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1 \n",
    "        x_train.append(cv2.resize(img, (image_size, image_size)))\n",
    "        y_train.append(targets)\n",
    "\n",
    "    for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "        img = cv2.imread(datapath + '/test-jpg/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (image_size, image_size)))\n",
    "\n",
    "    y_train = np.array(y_train, np.uint8)\n",
    "    x_train = np.array(x_train, np.float32)/255.\n",
    "    x_test  = np.array(x_test, np.float32)/255.\n",
    "    \n",
    "    return x_train, y_train, x_test, labels, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F2_score(threshold):\n",
    "    '''\n",
    "    【描述】\n",
    "    题目中评价函数的实现，可作为metrics传给keras模型, 可使本地的结果与提交结果接近\n",
    "    【输入参数】\n",
    "    threshold: 应与write_output函数中的threshold一致，预测值大于threshold被视为包含该标签\n",
    "    '''\n",
    "    def FScore2(y_true, y_pred):  \n",
    "        B2 = K.variable(4)\n",
    "        OnePlusB2 = K.variable(5)\n",
    "\n",
    "        threshold_ = K.variable(threshold)\n",
    "        pred = K.cast(K.greater(y_pred, threshold_), 'float32')\n",
    "\n",
    "        tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "        fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "        fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "        f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "        return K.mean(f2)\n",
    "    return FScore2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model=None, x_train=None, y_train=None, x_test=None, nfolds = 5, epochs_list = [5],\\\n",
    "              learning_rate_list = [0.001], weights_path = '../models/', batch_size=64,\\\n",
    "              loss='binary_crossentropy',metrics=['accuracy'], labels=None):\n",
    "    '''\n",
    "    【输入参数】\n",
    "    model: keras模型\n",
    "    x_train, y_train, x_test: 把get_model_input函数得到的相应变量传进来即可\n",
    "    nfolds: 进行几折交叉校验(cross validation)\n",
    "    epochs_list,learning_rate_list: 训练轮数和学习率的列表，长度必须相等，相同位置对应一种组合\n",
    "    weights_path: 保存模型权重的路径\n",
    "    batch_size, loss, metrics: 同keras中model.fit的同名参数\n",
    "    labels: 把get_model_input函数得到的相应变量传进来即可\n",
    "    【返回值】\n",
    "    模型对每个样本各个标签的预测值,值越大该样本越有可能包含该标签\n",
    "    '''\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "\n",
    "    yfull_test = []\n",
    "#     yfull_train =[]\n",
    "\n",
    "    kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n",
    "    \n",
    "    for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = os.path.join(weights_path, 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "        \n",
    "        epochs_arr = epochs_list\n",
    "        learn_rates = learning_rate_list\n",
    "\n",
    "        for learn_rate, epochs in zip(learn_rates, epochs_arr):\n",
    "            opt  = optimizers.Adam(lr=learn_rate)\n",
    "            model.compile(loss=loss,\n",
    "                          optimizer=opt,\n",
    "                          metrics=metrics)\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "            model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n",
    "        \n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "#         p_valid = model.predict(X_valid, batch_size = batch_size, verbose=2)\n",
    "#         print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "\n",
    "#         p_train = model.predict(x_train, batch_size =batch_size, verbose=2)\n",
    "#         yfull_train.append(p_train)\n",
    "        \n",
    "        p_test = model.predict(x_test, batch_size = batch_size, verbose=2)\n",
    "        yfull_test.append(p_test)\n",
    "    result = np.array(yfull_test[0])\n",
    "    \n",
    "    # 对nfolds次预测取平均\n",
    "    for i in range(1, nfolds):\n",
    "        result += np.array(yfull_test[i])\n",
    "    result /= nfolds\n",
    "    result = pd.DataFrame(result, columns = labels)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(result, output_path='../output/', file_name='test.csv', df_test=None, threshold=0.2):\n",
    "    '''\n",
    "    【输入参数】\n",
    "    result: 传入run_model函数的返回值即可\n",
    "    output_path: 结果文件的路径\n",
    "    file_name: 结果文件的名字\n",
    "    df_test: 传入get_model_input函数返回的相应变量即可\n",
    "    【输出】\n",
    "    写出文件到相应路径下\n",
    "    '''\n",
    "#     thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "    preds = []\n",
    "    for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "        a = result.ix[[i]]\n",
    "        a = a.apply(lambda x: x > threshold, axis=1)\n",
    "        a = a.transpose()\n",
    "        a = a.loc[a[i] == True]\n",
    "        ' '.join(list(a.index))\n",
    "        preds.append(' '.join(list(a.index)))\n",
    "\n",
    "    df_test['tags'] = preds\n",
    "    df_test.to_csv(output_path + file_name, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
